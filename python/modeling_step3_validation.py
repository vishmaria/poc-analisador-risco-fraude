# ============================================================================
# fraud_modeling_step3_validation.py - Valida√ß√£o Final
# ============================================================================

"""
Passo 3: Validar modelo em dados NUNCA VISTOS (VALIDATION.parquet)
- Carrega melhor modelo treinado
- Testa em VALIDATION.parquet (15%)
- Gera m√©tricas finais de produ√ß√£o
- Cria thresholds otimizados para detec√ß√£o de fraude
"""

import pandas as pd
import numpy as np
import pickle
import json
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    roc_auc_score, roc_curve, precision_recall_curve,
    f1_score, recall_score, precision_score, confusion_matrix,
    classification_report, accuracy_score
)
from sklearn.preprocessing import RobustScaler
import warnings
warnings.filterwarnings('ignore')

# ============================================================================
# CONFIGURA√á√ÉO
# ============================================================================

CONFIG = {
    'feature_cols': [
        'amount', 'newBalanceDest', 
        'CASH_IN', 'CASH_OUT', 'DEBIT', 'PAYMENT', 'TRANSFER',
        'amount_high', 'balance_suspicious', 'num_actions',
        'amount_balance_ratio', 'log_amount'
    ],
    'target_col': 'isFraud'
}

# ============================================================================
# VALIDA√á√ÉO
# ============================================================================

class FraudModelValidator:
    """Valida modelo em dados de produ√ß√£o"""
    
    def __init__(self, model_path):
        self.model = self._load_model(model_path)
        self.scaler = RobustScaler()
        self.results = {}
    
    def _load_model(self, path):
        """Carrega modelo treinado"""
        print(f"\nüìÇ Carregando modelo: {path}")
        with open(path, 'rb') as f:
            model = pickle.load(f)
        print(f"‚úì Modelo carregado com sucesso")
        return model
    
    def _create_features(self, df):
        """Cria features engenheiradas"""
        df_feat = df.copy()
        
        amount_mean = df['amount'].mean()
        df_feat['amount_high'] = (df['amount'] > amount_mean).astype(np.uint8)
        
        balance_q25 = df['newBalanceDest'].quantile(0.25)
        balance_q75 = df['newBalanceDest'].quantile(0.75)
        df_feat['balance_suspicious'] = (
            (df['newBalanceDest'] < balance_q25) | 
            (df['newBalanceDest'] > balance_q75)
        ).astype(np.uint8)
        
        action_cols = ['CASH_IN', 'CASH_OUT', 'DEBIT', 'PAYMENT', 'TRANSFER']
        df_feat['num_actions'] = df[action_cols].sum(axis=1)
        
        df_feat['amount_balance_ratio'] = np.where(
            df['newBalanceDest'] > 0,
            df['amount'] / (df['newBalanceDest'] + 1),
            0
        ).astype(np.float32)
        
        df_feat['log_amount'] = np.log1p(df['amount']).astype(np.float32)
        
        return df_feat
    
    def load_validation_data(self, validation_path):
        """Carrega dataset de valida√ß√£o"""
        
        print(f"\nüìÇ Carregando VALIDATION: {validation_path}")
        
        df_val = pd.read_parquet(validation_path)
        
        # Cria features se necess√°rio
        if 'amount_high' not in df_val.columns:
            print("üîß Criando features engenheiradas...")
            df_val = self._create_features(df_val)
        
        X_val = df_val[CONFIG['feature_cols']]
        y_val = df_val[CONFIG['target_col']]
        
        print(f"‚úì VALIDATION carregado: X={X_val.shape}, y={y_val.shape}")
        print(f"  Taxa de fraude: {(y_val == 1).sum() / len(y_val) * 100:.2f}%")
        
        return X_val, y_val
    
    def validate(self, X_val, y_val):
        """Executa valida√ß√£o completa"""
        
        print("\n" + "=" * 70)
        print("üî¨ VALIDA√á√ÉO EM DADOS N√ÉO VISTOS (VALIDATION.parquet)")
        print("=" * 70)
        
        # Escala dados
        X_val_scaled = self.scaler.fit_transform(X_val)
        X_val_scaled = pd.DataFrame(X_val_scaled, columns=CONFIG['feature_cols'])
        
        # Previs√µes
        y_pred = self.model.predict(X_val_scaled)
        y_pred_proba = self.model.predict_proba(X_val_scaled)[:, 1]
        
        # M√©tricas b√°sicas
        print("\nüìä M√âTRICAS DE VALIDA√á√ÉO")
        print("=" * 70)
        
        accuracy = accuracy_score(y_val, y_pred)
        precision = precision_score(y_val, y_pred)
        recall = recall_score(y_val, y_pred)
        f1 = f1_score(y_val, y_pred)
        roc_auc = roc_auc_score(y_val, y_pred_proba)
        
        print(f"\nüéØ M√âTRICAS PRINCIPAIS:")
        print(f"   Accuracy:  {accuracy:.4f}")
        print(f"   Precision: {precision:.4f} (de 100 alertas, {precision*100:.1f}% s√£o fraude real)")
        print(f"   Recall:    {recall:.4f} (encontra {recall*100:.1f}% das fraudes)")
        print(f"   F1-Score:  {f1:.4f}")
        print(f"   ROC-AUC:   {roc_auc:.4f}")
        
        # Matriz de confus√£o
        tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()
        
        print(f"\nüìã MATRIZ DE CONFUS√ÉO:")
        print(f"   Verdadeiro Negativo (TN):   {tn:,} (leg√≠timas corretamente identificadas)")
        print(f"   Falso Positivo (FP):        {fp:,} (leg√≠timas classificadas como fraude)")
        print(f"   Falso Negativo (FN):        {fn:,} (fraudes n√£o detectadas) ‚ö†Ô∏è")
        print(f"   Verdadeiro Positivo (TP):   {tp:,} (fraudes detectadas)")
        
        # Taxa de falsas fraudes
        if (tn + fp) > 0:
            false_alarm_rate = fp / (tn + fp) * 100
            print(f"\n   Taxa de falso alarme: {false_alarm_rate:.2f}%")
        
        # Armazena resultados
        self.results['validation'] = {
            'accuracy': float(accuracy),
            'precision': float(precision),
            'recall': float(recall),
            'f1': float(f1),
            'roc_auc': float(roc_auc),
            'confusion_matrix': {
                'tn': int(tn),
                'fp': int(fp),
                'fn': int(fn),
                'tp': int(tp)
            }
        }
        
        return {
            'y_pred': y_pred,
            'y_pred_proba': y_pred_proba,
            'metrics': self.results['validation']
        }
    
    def find_optimal_threshold(self, y_val, y_pred_proba):
        """Encontra threshold √≥timo para maximizar Recall (minimizar FN)"""
        
        print("\n\n" + "=" * 70)
        print("üéØ OTIMIZA√á√ÉO DE THRESHOLD")
        print("=" * 70)
        
        # Por padr√£o, o modelo usa 0.5
        # Mas para fraude, queremos HIGH RECALL (encontrar ao m√°ximo)
        
        fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)
        precision_vals, recall_vals, pr_thresholds = precision_recall_curve(y_val, y_pred_proba)
        
        # F1-score por threshold
        f1_scores = []
        for threshold in pr_thresholds:
            y_pred_opt = (y_pred_proba >= threshold).astype(int)
            f1 = f1_score(y_val, y_pred_opt)
            f1_scores.append(f1)
        
        # Threshold que maximiza F1
        optimal_threshold_f1 = pr_thresholds[np.argmax(f1_scores)]
        best_f1 = np.max(f1_scores)
        
        # Threshold para HIGH RECALL (encontrar mais fraudes)
        # Exemplo: encontrar 95% das fraudes
        target_recall = 0.95
        recall_idx = np.argmax(recall_vals >= target_recall)
        threshold_high_recall = pr_thresholds[recall_idx] if recall_idx < len(pr_thresholds) else 0.3
        
        print(f"\nüîß RECOMENDA√á√ïES DE THRESHOLD:")
        print(f"\n1. THRESHOLD PADR√ÉO (0.50)")
        print(f"   - Usa o padr√£o do modelo")
        print(f"   - Equil√≠brio Precision/Recall")
        
        print(f"\n2. THRESHOLD OTIMIZADO F1 ({optimal_threshold_f1:.3f})")
        print(f"   - Maximiza F1-Score: {best_f1:.4f}")
        print(f"   - Equil√≠brio entre Precision e Recall")
        
        y_pred_f1 = (y_pred_proba >= optimal_threshold_f1).astype(int)
        precision_f1 = precision_score(y_val, y_pred_f1)
        recall_f1 = recall_score(y_val, y_pred_f1)
        print(f"     Precision: {precision_f1:.4f} | Recall: {recall_f1:.4f}")
        
        print(f"\n3. THRESHOLD ALTO RECALL ({threshold_high_recall:.3f})")
        print(f"   - Prioriza encontrar fraudes ({target_recall*100:.0f}% minimum)")
        print(f"   - Trade-off: mais falsos positivos")
        
        y_pred_high_recall = (y_pred_proba >= threshold_high_recall).astype(int)
        precision_hr = precision_score(y_val, y_pred_high_recall)
        recall_hr = recall_score(y_val, y_pred_high_recall)
        print(f"     Precision: {precision_hr:.4f} | Recall: {recall_hr:.4f}")
        
        self.results['thresholds'] = {
            'default': 0.5,
            'optimal_f1': float(optimal_threshold_f1),
            'high_recall': float(threshold_high_recall)
        }
        
        return {
            'default': 0.5,
            'optimal_f1': optimal_threshold_f1,
            'high_recall': threshold_high_recall
        }
    
    def analyze_misclassifications(self, X_val, y_val, y_pred, y_pred_proba):
        """Analisa casos classificados incorretamente"""
        
        print("\n\n" + "=" * 70)
        print("üîç AN√ÅLISE DE ERROS")
        print("=" * 70)
        
        # Falsos positivos (leg√≠tima classificada como fraude)
        false_positives_idx = (y_val == 0) & (y_pred == 1)
        fp_count = false_positives_idx.sum()
        
        if fp_count > 0:
            print(f"\n‚ùå FALSOS POSITIVOS: {fp_count:,}")
            print(f"   Transa√ß√µes leg√≠timas alertadas como fraude")
            
            fp_amounts = X_val.loc[false_positives_idx, 'amount']
            print(f"   Amount m√©dio: ${fp_amounts.mean():,.2f}")
            print(f"   Confian√ßa m√©dia do modelo: {y_pred_proba[false_positives_idx].mean():.4f}")
        
        # Falsos negativos (fraude n√£o detectada)
        false_negatives_idx = (y_val == 1) & (y_pred == 0)
        fn_count = false_negatives_idx.sum()
        
        if fn_count > 0:
            print(f"\n‚ö†Ô∏è  FALSOS NEGATIVOS: {fn_count:,}")
            print(f"   Fraudes N√ÉO detectadas pelo modelo")
            print(f"   RISCO: Perdas financeiras!")
            
            fn_amounts = X_val.loc[false_negatives_idx, 'amount']
            print(f"   Amount m√©dio: ${fn_amounts.mean():,.2f}")
            print(f"   Confian√ßa m√©dia do modelo: {y_pred_proba[false_negatives_idx].mean():.4f}")
            
            print(f"\n   üí° A√á√ÉO: Investigar por qu√™ n√£o foram detectadas")
            print(f"      - Padr√£o novo de fraude?")
            print(f"      - Necess√°rio retreinar?")
    
    def generate_report(self, output_path='validation_report.json'):
        """Gera relat√≥rio final em JSON"""
        
        report = {
            'timestamp': pd.Timestamp.now().isoformat(),
            'dataset': 'VALIDATION.parquet',
            'results': self.results,
            'recommendations': {
                'next_steps': [
                    '‚úì Modelo est√° pronto para produ√ß√£o',
                    '‚úì Monitorar performance mensalmente',
                    '‚úì Alertar se ROC-AUC cair abaixo de 0.90',
                    '‚úì Retreinar se taxa de fraude mudar > 2%'
                ],
                'threshold_selection': 'Use optimal_f1 para produ√ß√£o'
            }
        }
        
        with open(output_path, 'w') as f:
            json.dump(report, f, indent=2, default=str)
        
        print(f"\nüíæ Relat√≥rio salvo em: {output_path}")
        
        return report

# ============================================================================
# EXECU√á√ÉO PASSO 3
# ============================================================================

if __name__ == "__main__":
    
    print("\n" + "=" * 70)
    print("üöÄ PASSO 3: VALIDA√á√ÉO FINAL EM DADOS N√ÉO VISTOS")
    print("=" * 70)
    
    # Carrega modelo
    validator = FraudModelValidator('models/best_fraud_model.pkl')
    
    # Carrega dados de valida√ß√£o
    X_val, y_val = validator.load_validation_data(
        'datasets/validation-00000-of-00001.parquet'
    )
    
    # Valida
    validation_results = validator.validate(X_val, y_val)
    
    # Encontra threshold √≥timo
    thresholds = validator.find_optimal_threshold(
        y_val, 
        validation_results['y_pred_proba']
    )
    
    # Analisa erros
    validator.analyze_misclassifications(
        X_val, y_val,
        validation_results['y_pred'],
        validation_results['y_pred_proba']
    )
    
    # Gera relat√≥rio
    report = validator.generate_report()
    
    print("\n" + "=" * 70)
    print("‚úÖ PASSO 3 CONCLU√çDO - MODELO VALIDADO E PRONTO PARA PRODU√á√ÉO")
    print("=" * 70)
    print(f"\nüìä ROC-AUC: {validation_results['metrics']['roc_auc']:.4f}")
    print(f"üéØ Recall: {validation_results['metrics']['recall']:.4f}")
    print(f"‚úÖ Threshold recomendado: {thresholds['optimal_f1']:.3f}")
